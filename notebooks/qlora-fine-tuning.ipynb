{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-01-19T13:15:39.222849Z","iopub.status.busy":"2024-01-19T13:15:39.222527Z","iopub.status.idle":"2024-01-19T13:17:34.966007Z","shell.execute_reply":"2024-01-19T13:17:34.964710Z","shell.execute_reply.started":"2024-01-19T13:15:39.222822Z"},"trusted":true},"outputs":[],"source":["!pip install -q -U bitsandbytes\n","!pip install -q -U git+https://github.com/huggingface/transformers.git\n","!pip install -q -U git+https://github.com/huggingface/peft.git\n","!pip install -q -U git+https://github.com/huggingface/accelerate.git"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:17:34.969170Z","iopub.status.busy":"2024-01-19T13:17:34.968351Z","iopub.status.idle":"2024-01-19T13:17:39.775211Z","shell.execute_reply":"2024-01-19T13:17:39.774250Z","shell.execute_reply.started":"2024-01-19T13:17:34.969139Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["bitsandbytes==0.42.0\n","accelerate @ git+https://github.com/huggingface/accelerate.git@649e65b542a5740fb5ce663bbd5af45ed426c06f\n"]}],"source":["!pip freeze | grep bitsandbytes\n","!pip freeze | grep accelerate"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:17:39.777101Z","iopub.status.busy":"2024-01-19T13:17:39.776757Z","iopub.status.idle":"2024-01-19T13:17:59.149191Z","shell.execute_reply":"2024-01-19T13:17:59.148045Z","shell.execute_reply.started":"2024-01-19T13:17:39.777072Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","++++++++++++++++++ BUG REPORT INFORMATION ++++++++++++++++++\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","++++++++++++++++++ /usr/local CUDA PATHS +++++++++++++++++++\n","/usr/local/nvidia/lib64/libcuda.so\n","/usr/local/cuda-11.8/targets/x86_64-linux/lib/libcudart.so\n","/usr/local/cuda-11.8/compat/libcuda.so\n","\n","+++++++++++++++ WORKING DIRECTORY CUDA PATHS +++++++++++++++\n","\n","\n","++++++++++++++++++ LD_LIBRARY CUDA PATHS +++++++++++++++++++\n","+++++++++++++ /usr/local/cuda/lib64 CUDA PATHS +++++++++++++\n","\n","++++++++++++ /usr/local/nvidia/lib64 CUDA PATHS ++++++++++++\n","/usr/local/nvidia/lib64/libcuda.so\n","++++++++++++++++ /opt/conda/lib CUDA PATHS +++++++++++++++++\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda110.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda122_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda115.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda122.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda123_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda121_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda120_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda111_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda115_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda114.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda110_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda114_nocublaslt.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda120.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda111.so\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda123.so\n","/opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda_linalg.so\n","/opt/conda/lib/python3.10/site-packages/torch/lib/libc10d_cuda_test.so\n","/opt/conda/lib/python3.10/site-packages/torch/lib/libtorch_cuda.so\n","/opt/conda/lib/python3.10/site-packages/torch/lib/libc10_cuda.so\n","/opt/conda/lib/python3.10/site-packages/pylibraft/common/cuda.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuml/common/cuda.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuda/tests/test_ccudart.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuda/tests/test_ccuda.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuda/cuda.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuda/ccudart.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuda/ccuda.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuda/cudart.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuda/_lib/ccudart/ccudart.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/cuda/_cuda/ccuda.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/python3.10/site-packages/rmm/_lib/cuda_stream.cpython-310-x86_64-linux-gnu.so\n","/opt/conda/lib/ucx/libucm_cuda.so\n","/opt/conda/lib/ucx/libucx_perftest_cuda.so\n","/opt/conda/lib/ucx/libuct_cuda.so\n","/opt/conda/lib/libcudart.so\n","/opt/conda/lib/libicudata.so\n","\n","++++++++++++++++++++++++++ OTHER +++++++++++++++++++++++++++\n","COMPILED_WITH_CUDA = True\n","COMPUTE_CAPABILITIES_PER_GPU = ['6.0']\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","++++++++++++++++++++++ DEBUG INFO END ++++++++++++++++++++++\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","\n","Running a quick check that:\n","    + library is importable\n","    + CUDA function is callable\n","\n","\n","WARNING: Please be sure to sanitize sensible info from any such env vars!\n","\n","SUCCESS!\n","Installation was successful!\n"]}],"source":["!python -m bitsandbytes"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:23:08.385091Z","iopub.status.busy":"2024-01-19T13:23:08.384673Z","iopub.status.idle":"2024-01-19T13:23:08.390551Z","shell.execute_reply":"2024-01-19T13:23:08.389625Z","shell.execute_reply.started":"2024-01-19T13:23:08.385059Z"},"trusted":true},"outputs":[],"source":["from transformers import (\n","    AutoModelForCausalLM,\n","    AutoModelForMaskedLM,\n","    AutoTokenizer,\n","    AutoConfig,\n","    PreTrainedModel,\n","    BitsAndBytesConfig,\n","    DataCollatorForLanguageModeling,\n","    TrainingArguments,\n","    Trainer\n",")\n","from peft import (\n","    prepare_model_for_kbit_training,\n","    LoraConfig,\n","    get_peft_model,\n","    get_peft_model_state_dict,\n",")\n","from datasets import load_from_disk, Dataset\n","import bitsandbytes as bnb\n","import torch\n","import accelerate"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:23:09.594822Z","iopub.status.busy":"2024-01-19T13:23:09.594487Z","iopub.status.idle":"2024-01-19T13:23:09.599033Z","shell.execute_reply":"2024-01-19T13:23:09.598114Z","shell.execute_reply.started":"2024-01-19T13:23:09.594795Z"},"trusted":true},"outputs":[],"source":["model_name = \"nlpie/distil-biobert\""]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:23:16.655823Z","iopub.status.busy":"2024-01-19T13:23:16.655431Z","iopub.status.idle":"2024-01-19T13:23:17.187459Z","shell.execute_reply":"2024-01-19T13:23:17.186710Z","shell.execute_reply.started":"2024-01-19T13:23:16.655792Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n","If you want to use `BertLMHeadModel` as a standalone, add `is_decoder=True.`\n"]}],"source":["qlora = False\n","\n","if qlora:\n","    qlora_config = LoraConfig(\n","        r=16,\n","        lora_alpha=32,\n","        lora_dropout=0.05,\n","        bias=\"none\",\n","        target_modules=[\"query_key_value\", \"dense\", \"dense_h_to_4h\", \"dense_4h_to_h\"],\n","        task_type=\"CAUSAL_LM\"\n","    )\n","\n","    bnb_config = BitsAndBytesConfig(\n","        load_in_4bit=True,\n","        bnb_4bit_use_double_quant=True,\n","        bnb_4bit_quant_type=\"nf4\",\n","        bnb_4bit_compute_dtype=torch.bfloat16\n","    )\n","\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        trust_remote_code=True,\n","        quantization_config=bnb_config,\n","    )\n","    \n","    model = prepare_model_for_kbit_training(model)\n","    model = get_peft_model(model, qlora_config)\n","else:\n","    model = AutoModelForCausalLM.from_pretrained(\n","        model_name,\n","        trust_remote_code=True,\n","    )\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","tokenizer.pad_token = tokenizer.eos_token"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:23:18.711481Z","iopub.status.busy":"2024-01-19T13:23:18.711117Z","iopub.status.idle":"2024-01-19T13:23:24.201679Z","shell.execute_reply":"2024-01-19T13:23:24.200735Z","shell.execute_reply.started":"2024-01-19T13:23:18.711452Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d656476c04b94cb281eb07785cb87b90","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/34 [00:00<?, ?ba/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["(Dataset({\n","     features: ['input_ids'],\n","     num_rows: 33691\n"," }),\n"," DatasetDict({\n","     train: Dataset({\n","         features: ['input_ids'],\n","         num_rows: 33354\n","     })\n","     test: Dataset({\n","         features: ['input_ids'],\n","         num_rows: 337\n","     })\n"," }),\n"," Dataset({\n","     features: ['input_ids'],\n","     num_rows: 33354\n"," }),\n"," Dataset({\n","     features: ['input_ids'],\n","     num_rows: 337\n"," }))"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","dataframe = pd.read_csv(\"/kaggle/input/altegrad-2023/text.csv\")\n","dataset = Dataset.from_pandas(dataframe)\n","\n","context_length = 256\n","\n","def tokenize(element):\n","    outputs = tokenizer(\n","        element[\"text\"],\n","        truncation=True,\n","        max_length=context_length,\n","        return_overflowing_tokens=True,\n","        return_length=True,\n","    )\n","    return {\"input_ids\": outputs[\"input_ids\"]}\n","\n","tokenized_dataset = dataset.map(\n","    tokenize, batched=True, remove_columns=dataset.column_names\n",")\n","split_dataset = tokenized_dataset.train_test_split(test_size=0.01)\n","train_dataset = split_dataset[\"train\"]\n","eval_dataset = split_dataset[\"test\"]\n","tokenized_dataset, split_dataset, train_dataset, eval_dataset"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:27:10.880794Z","iopub.status.busy":"2024-01-19T13:27:10.880405Z","iopub.status.idle":"2024-01-19T13:27:10.889966Z","shell.execute_reply":"2024-01-19T13:27:10.889049Z","shell.execute_reply.started":"2024-01-19T13:27:10.880763Z"},"trusted":true},"outputs":[],"source":["OUTPUT_DIR = \"/kaggle/working/checkpoint\"\n","\n","if qlora:\n","    training_args = TrainingArguments(\n","        evaluation_strategy=\"steps\",\n","        per_device_train_batch_size=8,\n","        per_device_eval_batch_size=8,\n","\n","        num_train_epochs=4,\n","\n","        learning_rate=5e-4,\n","        lr_scheduler_type=\"cosine\",\n","\n","        save_steps=500,\n","        eval_steps=100,\n","        logging_steps=100,\n","\n","        seed=42,\n","        fp16=True,\n","        optim=\"paged_adamw_8bit\",\n","\n","        warmup_steps=500,\n","        gradient_accumulation_steps=8,\n","\n","        load_best_model_at_end=True,\n","\n","        # resume_from_checkpoint=OUTPUT_DIR,\n","        output_dir=OUTPUT_DIR,\n","        save_total_limit=5,\n","        report_to=\"none\"\n","    )\n","else:\n","    training_args = TrainingArguments(\n","        evaluation_strategy=\"steps\",\n","        per_device_train_batch_size=16,\n","        per_device_eval_batch_size=16,\n","\n","        num_train_epochs=5,\n","\n","        learning_rate=5e-4,\n","        lr_scheduler_type=\"cosine\",\n","\n","        save_steps=250,\n","        eval_steps=50,\n","        logging_steps=50,\n","\n","        seed=42,\n","        fp16=False,\n","\n","        weight_decay=0.1,\n","        warmup_steps=175,\n","        gradient_accumulation_steps=8,\n","\n","        load_best_model_at_end=True,\n","\n","        # resume_from_checkpoint=OUTPUT_DIR,\n","        output_dir=OUTPUT_DIR,\n","        save_total_limit=5,\n","        report_to=\"none\"\n","    )"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:27:11.461237Z","iopub.status.busy":"2024-01-19T13:27:11.460957Z","iopub.status.idle":"2024-01-19T13:27:11.465473Z","shell.execute_reply":"2024-01-19T13:27:11.464651Z","shell.execute_reply.started":"2024-01-19T13:27:11.461214Z"},"trusted":true},"outputs":[],"source":["from transformers import DataCollatorForLanguageModeling\n","tokenizer.pad_token = \"[PAD]\"\n","data_collator = DataCollatorForLanguageModeling(\n","    tokenizer=tokenizer, mlm=False\n",")\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:27:12.205860Z","iopub.status.busy":"2024-01-19T13:27:12.205529Z","iopub.status.idle":"2024-01-19T13:44:30.579638Z","shell.execute_reply":"2024-01-19T13:44:30.578481Z","shell.execute_reply.started":"2024-01-19T13:27:12.205834Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='513' max='1300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 513/1300 17:14 < 26:33, 0.49 it/s, Epoch 1.96/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>50</td>\n","      <td>0.533300</td>\n","      <td>0.032736</td>\n","    </tr>\n","    <tr>\n","      <td>100</td>\n","      <td>0.023100</td>\n","      <td>0.002331</td>\n","    </tr>\n","    <tr>\n","      <td>150</td>\n","      <td>0.006400</td>\n","      <td>0.000988</td>\n","    </tr>\n","    <tr>\n","      <td>200</td>\n","      <td>0.004000</td>\n","      <td>0.000724</td>\n","    </tr>\n","    <tr>\n","      <td>250</td>\n","      <td>0.003800</td>\n","      <td>0.000344</td>\n","    </tr>\n","    <tr>\n","      <td>300</td>\n","      <td>0.002800</td>\n","      <td>0.001639</td>\n","    </tr>\n","    <tr>\n","      <td>350</td>\n","      <td>0.004500</td>\n","      <td>0.000322</td>\n","    </tr>\n","    <tr>\n","      <td>400</td>\n","      <td>0.002000</td>\n","      <td>0.000066</td>\n","    </tr>\n","    <tr>\n","      <td>450</td>\n","      <td>0.001300</td>\n","      <td>0.000088</td>\n","    </tr>\n","    <tr>\n","      <td>500</td>\n","      <td>0.000900</td>\n","      <td>0.000034</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1874\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1878\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["trainer = Trainer(\n","    model=model,\n","    tokenizer=tokenizer,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset,\n","    args=training_args,\n","    data_collator=data_collator,\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-01-19T13:49:45.880182Z","iopub.status.busy":"2024-01-19T13:49:45.879760Z","iopub.status.idle":"2024-01-19T13:51:04.534753Z","shell.execute_reply":"2024-01-19T13:51:04.533750Z","shell.execute_reply.started":"2024-01-19T13:49:45.880150Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/checkpoint/checkpoint-250/ (stored 0%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/vocab.txt (deflated 49%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/optimizer.pt (deflated 7%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/tokenizer.json (deflated 70%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/rng_state.pth (deflated 28%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/trainer_state.json (deflated 72%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/config.json (deflated 50%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/generation_config.json (deflated 8%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/scheduler.pt (deflated 49%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/tokenizer_config.json (deflated 76%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/training_args.bin (deflated 49%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/special_tokens_map.json (deflated 76%)\n","  adding: kaggle/working/checkpoint/checkpoint-250/model.safetensors (deflated 7%)\n"]},{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/checkpoint/checkpoint-500/ (stored 0%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/vocab.txt (deflated 49%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/optimizer.pt (deflated 7%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/tokenizer.json (deflated 70%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/rng_state.pth (deflated 28%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/trainer_state.json (deflated 77%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/config.json (deflated 50%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/generation_config.json (deflated 8%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/scheduler.pt (deflated 49%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/tokenizer_config.json (deflated 76%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/training_args.bin (deflated 49%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/special_tokens_map.json (deflated 76%)\n","  adding: kaggle/working/checkpoint/checkpoint-500/model.safetensors (deflated 7%)\n"]}],"source":["!zip -r checkpoint-250.zip /kaggle/working/checkpoint/checkpoint-250\n","!zip -r checkpoint-500.zip /kaggle/working/checkpoint/checkpoint-500"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4322428,"sourceId":7428116,"sourceType":"datasetVersion"},{"datasetId":4327036,"sourceId":7435095,"sourceType":"datasetVersion"}],"dockerImageVersionId":30636,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}

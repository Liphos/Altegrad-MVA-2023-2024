{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataloader import GraphDataset, GraphTextDataset, TextDataset, GraphTextInMDataset\n",
    "import networkx as nx\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "source_directory = r\"C:\\Antoine\\Study\\Master 2 - MVA\\ALTEGRAD\\Challenge\\Public\\Public\\data\"\n",
    "destination_directory = r\"C:\\Antoine\\Study\\Master 2 - MVA\\ALTEGRAD\\Altegrad-MVA-2023-2024\\data\"\n",
    "\n",
    "def move_files(source_directory, destination_directory):\n",
    "    # Make sure the destination directory exists, create it if not\n",
    "    if not os.path.exists(destination_directory):\n",
    "        os.makedirs(destination_directory)\n",
    "\n",
    "    # Get the total number of files to track progress\n",
    "    total_files = sum([len(files) for _, _, files in os.walk(source_directory)])\n",
    "\n",
    "    # Initialize the tqdm progress bar\n",
    "    progress_bar = tqdm(total=total_files, desc=\"Moving files\", unit=\"file\")\n",
    "\n",
    "    # Walk through the source directory and its subdirectories\n",
    "    for root, _, files in os.walk(source_directory):\n",
    "        for file_name in files:\n",
    "            source_path = os.path.join(root, file_name)\n",
    "            # Create the corresponding subdirectory structure in the destination\n",
    "            relative_path = os.path.relpath(source_path, source_directory)\n",
    "            destination_path = os.path.join(destination_directory, relative_path)\n",
    "\n",
    "            destination_dir = os.path.dirname(destination_path)\n",
    "            if not os.path.exists(destination_dir):\n",
    "                os.makedirs(destination_dir)\n",
    "\n",
    "\n",
    "            # Move the file\n",
    "            shutil.move(source_path, destination_path)\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "\n",
    "    # Close the progress bar\n",
    "    progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move_files(source_directory, destination_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r\"data/processed/train/\"\n",
    "test_dir = r\"data/processed/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = torch.load(train_dir + \"data.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datasets(tokenizer: AutoTokenizer):\n",
    "    gt = np.load(\"./data/token_embedding_dict.npy\", allow_pickle=True)[()]\n",
    "    val_dataset = GraphTextInMDataset(\n",
    "        root=\"./data/\", gt=gt, split=\"val\", tokenizer=tokenizer\n",
    "    )\n",
    "    train_dataset = GraphTextInMDataset(\n",
    "        root=\"./data/\", gt=gt, split=\"train\", tokenizer=tokenizer\n",
    "    )\n",
    "    return val_dataset, train_dataset\n",
    "\n",
    "val_dataset, train_dataset = load_datasets(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_dataset[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_sample(sample):\n",
    "    edges = sample.edge_index\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add edges to the graph\n",
    "    for i in range(len(edges[0])):\n",
    "        G.add_edge(int(edges[0][i]), int(edges[1][i]))\n",
    "\n",
    "    # Draw the graph\n",
    "    pos = nx.kamada_kawai_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, font_size=8, node_color='skyblue', node_size=200, edge_color='gray', linewidths=0.3, arrows=False)\n",
    "\n",
    "    # Show the plot\n",
    "    decoded_input = tokenizer.batch_decode(sample.input_ids, skip_special_tokens=True)[0]\n",
    "    wrapped_text = textwrap.fill(decoded_input, width=70)\n",
    "\n",
    "    plt.text(0, -1, wrapped_text, ha='center', va='center', fontsize=8, bbox=dict(facecolor='white', alpha=0.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "show_sample(train_dataset[41])\n",
    "plt.subplot(2, 2, 2)\n",
    "show_sample(train_dataset[121])\n",
    "plt.subplot(2, 2, 3)\n",
    "show_sample(train_dataset[452])\n",
    "plt.subplot(2, 2, 4)\n",
    "show_sample(train_dataset[71])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name C:\\Users\\Antoine/.cache\\torch\\sentence_transformers\\microsoft_BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_input = tokenizer.batch_decode(train_dataset[41].input_ids, skip_special_tokens=True)[0]\n",
    "print(decoded_input)\n",
    "embedding = model.encode(\n",
    "    decoded_input\n",
    ")\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = pd.read_csv(\"./data/train.tsv\", sep=\"\\t\")\n",
    "val_ds = pd.read_csv(\"./data/val.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Read data/test_text.txt into a list of strings\n",
    "with open(\"./data/test_text.txt\", \"r\") as f:\n",
    "    test_text = f.readlines()\n",
    "\n",
    "test_text = [text.strip() for text in test_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = train_ds.iloc[:, 1].tolist() + val_ds.iloc[:, 1].tolist() + test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_100860\\293564427.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save to pandas dataframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./data/text.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Save to pandas dataframe\n",
    "df = pd.DataFrame(ds, columns=[\"text\"])\n",
    "df.to_csv(\"./data/text.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate the text to 512 tokens and add overflow to new rows\n",
    "df = pd.read_csv(\"./data/text.csv\")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext')\n",
    "\n",
    "def preprocess(samples):\n",
    "    batch_size = 64\n",
    "\n",
    "    tokenized = []\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        tokenized.append(tokenizer(samples[\"text\"][i:i+batch_size].tolist(), truncation=True, max_length=256, return_overflowing_tokens=True))\n",
    "    return tokenized\n",
    "\n",
    "tokenized = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 22, 17, 4118, 25238, 1037, 17, 22, 17, 163...</td>\n",
       "      <td>[2, 22, 17, 4118, 25238, 1037, 17, 22, 17, 163...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 19406, 1935, 2687, 1977, 1925, 4595, 16, 1...</td>\n",
       "      <td>[2, 19406, 1935, 2687, 1977, 1925, 4595, 16, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 2136, 17, 2127, 17, 24, 17, 18588, 28038, ...</td>\n",
       "      <td>[2, 2136, 17, 2127, 17, 24, 17, 18588, 28038, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 7843, 22, 17, 20990, 2928, 9286, 2010, 197...</td>\n",
       "      <td>[2, 7843, 22, 17, 20990, 2928, 9286, 2010, 197...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 10534, 5405, 2053, 12, 21, 15, 13, 1977, 1...</td>\n",
       "      <td>[2, 10534, 5405, 2053, 12, 21, 15, 13, 1977, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[2, 12, 17659, 13, 17, 24321, 11800, 11123, 19...</td>\n",
       "      <td>[2, 12, 17659, 13, 17, 24321, 11800, 11123, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[2, 12, 24, 17, 20990, 22467, 2199, 13, 29141,...</td>\n",
       "      <td>[2, 12, 24, 17, 20990, 22467, 2199, 13, 29141,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[2, 8298, 4151, 2057, 1977, 43, 3421, 5482, 19...</td>\n",
       "      <td>[2, 8298, 4151, 2057, 1977, 43, 3421, 5482, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[2, 54, 17, 13489, 5482, 12, 21, 15, 13, 1977,...</td>\n",
       "      <td>[2, 54, 17, 13489, 5482, 12, 21, 15, 13, 1977,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[2, 26, 17, 21392, 2762, 14560, 17, 23, 11, 17...</td>\n",
       "      <td>[2, 26, 17, 21392, 2762, 14560, 17, 23, 11, 17...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   [2, 22, 17, 4118, 25238, 1037, 17, 22, 17, 163...   \n",
       "1   [2, 19406, 1935, 2687, 1977, 1925, 4595, 16, 1...   \n",
       "2   [2, 2136, 17, 2127, 17, 24, 17, 18588, 28038, ...   \n",
       "3   [2, 7843, 22, 17, 20990, 2928, 9286, 2010, 197...   \n",
       "4   [2, 10534, 5405, 2053, 12, 21, 15, 13, 1977, 1...   \n",
       "..                                                ...   \n",
       "43  [2, 12, 17659, 13, 17, 24321, 11800, 11123, 19...   \n",
       "44  [2, 12, 24, 17, 20990, 22467, 2199, 13, 29141,...   \n",
       "45  [2, 8298, 4151, 2057, 1977, 43, 3421, 5482, 19...   \n",
       "46  [2, 54, 17, 13489, 5482, 12, 21, 15, 13, 1977,...   \n",
       "47  [2, 26, 17, 21392, 2762, 14560, 17, 23, 11, 17...   \n",
       "\n",
       "                                            input_ids  \\\n",
       "0   [2, 22, 17, 4118, 25238, 1037, 17, 22, 17, 163...   \n",
       "1   [2, 19406, 1935, 2687, 1977, 1925, 4595, 16, 1...   \n",
       "2   [2, 2136, 17, 2127, 17, 24, 17, 18588, 28038, ...   \n",
       "3   [2, 7843, 22, 17, 20990, 2928, 9286, 2010, 197...   \n",
       "4   [2, 10534, 5405, 2053, 12, 21, 15, 13, 1977, 1...   \n",
       "..                                                ...   \n",
       "43  [2, 12, 17659, 13, 17, 24321, 11800, 11123, 19...   \n",
       "44  [2, 12, 24, 17, 20990, 22467, 2199, 13, 29141,...   \n",
       "45  [2, 8298, 4151, 2057, 1977, 43, 3421, 5482, 19...   \n",
       "46  [2, 54, 17, 13489, 5482, 12, 21, 15, 13, 1977,...   \n",
       "47  [2, 26, 17, 21392, 2762, 14560, 17, 23, 11, 17...   \n",
       "\n",
       "                                       attention_mask  \n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "..                                                ...  \n",
       "43  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "44  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "45  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "46  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "47  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[33331 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"text\", \"input_ids\", \"attention_mask\"])\n",
    "for i in range(len(tokenized)):\n",
    "    # df = df.append(pd.DataFrame({\n",
    "    #     \"text\": tokenized[i][\"input_ids\"],\n",
    "    #     \"input_ids\": tokenized[i][\"input_ids\"],\n",
    "    #     \"attention_mask\": tokenized[i][\"attention_mask\"],\n",
    "    # }))\n",
    "    # Change append to concat\n",
    "    df = pd.concat([df, pd.DataFrame({\n",
    "        \"text\": tokenized[i][\"input_ids\"],\n",
    "        \"input_ids\": tokenized[i][\"input_ids\"],\n",
    "        \"attention_mask\": tokenized[i][\"attention_mask\"],\n",
    "    })])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 22, 17, 4118, 25238, 1037, 17, 22, 17, 163...</td>\n",
       "      <td>[2, 22, 17, 4118, 25238, 1037, 17, 22, 17, 163...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 19406, 1935, 2687, 1977, 1925, 4595, 16, 1...</td>\n",
       "      <td>[2, 19406, 1935, 2687, 1977, 1925, 4595, 16, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 2136, 17, 2127, 17, 24, 17, 18588, 28038, ...</td>\n",
       "      <td>[2, 2136, 17, 2127, 17, 24, 17, 18588, 28038, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 7843, 22, 17, 20990, 2928, 9286, 2010, 197...</td>\n",
       "      <td>[2, 7843, 22, 17, 20990, 2928, 9286, 2010, 197...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 10534, 5405, 2053, 12, 21, 15, 13, 1977, 1...</td>\n",
       "      <td>[2, 10534, 5405, 2053, 12, 21, 15, 13, 1977, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[2, 12, 17659, 13, 17, 24321, 11800, 11123, 19...</td>\n",
       "      <td>[2, 12, 17659, 13, 17, 24321, 11800, 11123, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[2, 12, 24, 17, 20990, 22467, 2199, 13, 29141,...</td>\n",
       "      <td>[2, 12, 24, 17, 20990, 22467, 2199, 13, 29141,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[2, 8298, 4151, 2057, 1977, 43, 3421, 5482, 19...</td>\n",
       "      <td>[2, 8298, 4151, 2057, 1977, 43, 3421, 5482, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[2, 54, 17, 13489, 5482, 12, 21, 15, 13, 1977,...</td>\n",
       "      <td>[2, 54, 17, 13489, 5482, 12, 21, 15, 13, 1977,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[2, 26, 17, 21392, 2762, 14560, 17, 23, 11, 17...</td>\n",
       "      <td>[2, 26, 17, 21392, 2762, 14560, 17, 23, 11, 17...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33331 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  \\\n",
       "0   [2, 22, 17, 4118, 25238, 1037, 17, 22, 17, 163...   \n",
       "1   [2, 19406, 1935, 2687, 1977, 1925, 4595, 16, 1...   \n",
       "2   [2, 2136, 17, 2127, 17, 24, 17, 18588, 28038, ...   \n",
       "3   [2, 7843, 22, 17, 20990, 2928, 9286, 2010, 197...   \n",
       "4   [2, 10534, 5405, 2053, 12, 21, 15, 13, 1977, 1...   \n",
       "..                                                ...   \n",
       "43  [2, 12, 17659, 13, 17, 24321, 11800, 11123, 19...   \n",
       "44  [2, 12, 24, 17, 20990, 22467, 2199, 13, 29141,...   \n",
       "45  [2, 8298, 4151, 2057, 1977, 43, 3421, 5482, 19...   \n",
       "46  [2, 54, 17, 13489, 5482, 12, 21, 15, 13, 1977,...   \n",
       "47  [2, 26, 17, 21392, 2762, 14560, 17, 23, 11, 17...   \n",
       "\n",
       "                                            input_ids  \\\n",
       "0   [2, 22, 17, 4118, 25238, 1037, 17, 22, 17, 163...   \n",
       "1   [2, 19406, 1935, 2687, 1977, 1925, 4595, 16, 1...   \n",
       "2   [2, 2136, 17, 2127, 17, 24, 17, 18588, 28038, ...   \n",
       "3   [2, 7843, 22, 17, 20990, 2928, 9286, 2010, 197...   \n",
       "4   [2, 10534, 5405, 2053, 12, 21, 15, 13, 1977, 1...   \n",
       "..                                                ...   \n",
       "43  [2, 12, 17659, 13, 17, 24321, 11800, 11123, 19...   \n",
       "44  [2, 12, 24, 17, 20990, 22467, 2199, 13, 29141,...   \n",
       "45  [2, 8298, 4151, 2057, 1977, 43, 3421, 5482, 19...   \n",
       "46  [2, 54, 17, 13489, 5482, 12, 21, 15, 13, 1977,...   \n",
       "47  [2, 26, 17, 21392, 2762, 14560, 17, 23, 11, 17...   \n",
       "\n",
       "                                       attention_mask  \n",
       "0   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4   [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "..                                                ...  \n",
       "43  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "44  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "45  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "46  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "47  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "\n",
       "[33331 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.to_csv(\"./data/text_tokenized.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
